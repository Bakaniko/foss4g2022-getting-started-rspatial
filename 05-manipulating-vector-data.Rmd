# Manipulating vector data {#manipulating-vector-data}

<!-- (Nicolas) Vector data processing (45 min) -->

For this part, we will mostly use {sf} capabilities. 
Its most spatial functions start with the `st_` (*for spatial type*) 
prefix like in [PostGIS](https://postgis.net/docs/manual-2.5/reference.html).

We will use vector data from the {spData} package.
We will also use functions from the {dplyr} package as {sf} objects are data frames
compatible with the Tidyverse philosophy.

```{r libraries}
library(sf)
library(spData)
library(dplyr)
library(tmap)
library(here)
```

## Read spatial data

{sf} provides the `read_sf()` and `write_sf()` functions to access geospatial files. 
They can operate with any [vector driver provided by GDAL](https://gdal.org/drivers/vector/index.html).

We will use the data from the {spData} package.^[More details on the datasets here:
[https://cran.r-project.org/web/packages/spData/spData.pdf](https://cran.r-project.org/web/packages/spData/spData.pdf)]
Let's see what it contains:

```{r spData_files}
list.files(system.file("shapes", package = "spData"))
```

We will work on cycle hires points in London, so let's start by loading that data.

### Cycle hire dataset

```{r load_hire_data}
cycle_hire <- read_sf(system.file("shapes/cycle_hire.geojson", package = "spData"))
cycle_hire
```

Here we can see a couple of functions :

* `read_sf()` is the reading function from {sf}
* `system.file()` is a function that allow us to look for data in packages, independently of the operating system

By default, {sf} provides informations when loading the dataset. 
We can see it contains 742 features and 5 fields. 
It has points with lat/lon coordinates (we can see it through information about its CRS: `Geodetic CRS:  WGS 84`). 
{sf} also shows the bounding box of our object.

Here is the description of the dataset from the documentation: 

:::: {.infobox .tip data-latex="note"}

**cycle_hire dataset**
  
~Description:~ Points representing cycle hire points accross London.

~Format:~
  
 *  **id** Id of the hire point
 *  **name** Name of the point
 *  **area** Area they are in
 *  **nbikes** The number of bikes currently parked there  
 *  **nempty** The number of empty places
 *  *geometry* sfc_POINT

~Source~: [cyclehireapp.com/cyclehirelive/cyclehire.csv](cyclehireapp.com/cyclehirelive/cyclehire.csv)

::::

We can see how many bike are parked, the count of empty slots but not the total amount of bike slots. 
Let's create a new `slots` column for this with `mutate()` from {dplyr}.

```{r create_bike_slots}
cycle_hire <- mutate(cycle_hire, slots = nbikes + nempty)
```

Now, let's load a polygon data, in this case London's boroughs stored in the `lnd` dataset.

### Boroughs of London

This dataset is stored in an R data format so the loading is different.

```{r loading_lnd}
data(lnd) # load the dataset in memory
lnd       # call the dataset to visualize the 10 first features
```

We can see this dataset has 33 features and 7 fields, also in lat/lon coordinates.
The geometry type i, however, different: MULTIPOLYGON.

:::: {.infobox .tip data-latex="note"}

**ldn dataset**

The boroughs of London

Description : Polygons representing large administrative zones in London

Format:
  
  *  **NAME** Borough name
  *  **GSS_CODE** Official code
  *  **HECTARES** How many hectares
  *  **NONLD_AREA** Area outside London
  *  **ONS_INNER** Office for national statistics code
  *  **SUB_2009** Empty column
  *  **SUB_2006** Empty column
  *  *geometry* sfc_MULTIPOLYGON

Source : [https://github.com/Robinlovelace/Creating-maps-in-R](https://github.com/Robinlovelace/Creating-maps-in-R)

::::

In order to ease spatial calculations, let's reproject them.

## Reprojection {#reprojection}

The [Ordnance Survey National Grid](https://en.wikipedia.org/wiki/Ordnance_Survey_National_Grid) is the official one for Great Britain. 
Its SRID is **EPSG:27700**.

```{r data_reprojection}
cycle_hire_27700 <- st_transform(cycle_hire, crs = "EPSG:27700")
london_27700 <- st_transform(lnd, crs = "EPSG:27700")
```

We used `st_transform()` for the reprojection operation.
We can also use `st_crs()` to check the CRS definition of our objects.

Now, we can create a quick map using the the `plot()` function.
This function is part of base R.

```{r quick_plot}
plot(london_27700$geometry) # we just want to plot the geometry column
plot(cycle_hire_27700$geometry, 
 col = "red",  # color
 cex = 0.5,    # size of symbol
 add = TRUE)   # important parameter to create multilayer plots
```

We could also use {tmap} here:

```{r}
tm_shape(london_27700) +
  tm_borders() +
  tm_shape(cycle_hire_27700) +
  tm_symbols(size = 0.5, col = "red")
```

## Joins

We can use two ways to link those datasets together, by attributes (as they share their area name (`area` and `NAME`)) or spatially. 
For the sake of the exercise, let's do both.

### Join by attributes

Let's join them with a inner join to see how many corresponds.

```{r inner_attribute_join}
inner_join(cycle_hire_27700,
  st_drop_geometry(london_27700), # we don't need the geometry here
  by = c( "area" = "NAME")
)
```

We can see that only 33 features matched. 
That's poor, let's try this spatially.

### Spatial join

For this, we will try to provide a `GSS_CODE` for all cycle hire points. 
We will regroup the data afterwards.

For this, we will select only the `GSS_CODE` column from `london_27700` with the
`select()` function from {dplyr}, the geometry will follow.

```{r spatial_join}
cycle_hire_27700 <- st_join(cycle_hire_27700, select(london_27700, GSS_CODE))
```

Now if we look at our dataset, there is a `GSS_CODE` column.

```{r names_cycle_hire}
names(cycle_hire_27700)
```

How many points doesn't have a GSS_code?

```{r controle_nas}
filter(cycle_hire_27700, is.na(GSS_CODE))
```

Only one, that's more better than before! 
I don't know well enough London to fix this. 
But that is not prevening us from the next steps.

Now to paraphrase Anita Graser: [*"Aggregate all the things!"*](https://anitagraser.com/2017/06/08/aggregate-all-the-things-qgis-expression-edition/)

## Aggregation

### Count

```{r aggregation_count}
# remove NAs
cycle_hire_clean <- filter(cycle_hire_27700, !is.na(GSS_CODE))
# let's put geometry aside
cycle_hire_clean <- st_drop_geometry(cycle_hire_clean)
# group data by GSS_CODE
cycle_hire_grouped <- group_by(cycle_hire_clean, GSS_CODE)
# count
cycle_hire_by_area <- tally(cycle_hire_grouped, name = "count", sort= TRUE) # Aggregate
cycle_hire_by_area
```

:::: {.infobox .tip data-latex="tip"}

`tally()` is equivalent to `df %>% summarise(n = n())`

::::

### Sum

```{r aggregation_sum}
# count
cycle_hire_by_area_sum <- summarise(
  cycle_hire_grouped, # we reused grouped data
  sum = sum(nbikes), # sums the number of bikes
  count = n() # count cycle stations
  ) 
cycle_hire_by_area_sum
```

We could have use the base function `aggregate()` which works with `sf` objects.

```{r aggregate_alternative}
aggregate(cycle_hire_27700["nbikes"], 
          by = list(cycle_hire_27700$"GSS_CODE"),
          FUN = sum, 
          na.rm = TRUE)
```

If we want to represents our data with proportional symbols, we might want to create centroids. 
{sf} provides two functions in order to do that:

* `st_centroid()`
* `st_point_on_surface()`

`st_point_on_surface()` assures that every point is **in** its polygon. 
That can be useful for irregular shapes where the centroid might be outside the shape.

## Centroids

```{r centroids}
 # only keep useful columns
boroughs <- select(london_27700, NAME, GSS_CODE)
# compute centroids
boroughs_centroids <- st_centroid(boroughs)
```

You can also do buffers and other geometrical operations like [`st_union()`](https://r-spatial.github.io/sf/reference/geos_combine.html) to merge geometries.

![Spatial equivalents of logical operators [@lovelace_geocomputation_2019]](images/venn-clip-1.png)

## Geometric binary predicates

{sf} provides numerous geometric binary predicates that can be used with the intersection function.

* `st_intersects()`
* `st_disjoint()`
* `st_touches()`
* `st_crosses()`
* `st_within()`
* `st_contains()`
* `st_contains_properly()`
* `st_overlaps()`
* `st_equals()`
* `st_covers()`
* `st_covered_by()`
* `st_equals_exact()`
* `st_is_within_distance()`

You can use it alone or together with `st_join()`. 

For example, if we want to get the cycle hires contained in the borough of Wandsworth, 
we will do it like this:

```{r find_E09000032}
Wandsworth <- filter(london_27700, NAME == "Wandsworth")
(Wandsworth_bike_stations <- st_contains(Wandsworth, cycle_hire_27700) )
```

That will return a list of cycle hire points id.

In contrary, if we want to find in which borough the hire point with id 614 is, we can use the opposite function `st_within()`:

```{r borough_of_614}
cycle_hire_614 <- filter(cycle_hire_27700, id == "614") 
cycle_hire_614_borough <- st_within(cycle_hire_614, london_27700) # borough at index 22
cycle_hire_614_borough
```

To get the borough data, there is some more work to do.

```{r get_borough22}
london_27700[unlist(cycle_hire_614_borough), ]
```

## Saving results

In the first part, we saw that we can read spatial vector data but we can also write it!

### Writing data

To write data, we will use the `st_write()` function.
It takes the data source name (*dsn*) as mandatory argument, {sf} will try to find the good driver from the extension (here it is *.gpkg* for GeoPackage).

```{block2, type='rmdwarning'}
*write_sf()* can't save non geospatial data.
So we need to join the data from cycle_hire_by_area_sum to the boroughs first.
```

As we want to save it to GeoPackage^[Because [GeoPackage are cool !](http://switchfromshapefile.org/#geopackage)], we also need to provide a layer name: *london_boroughs_27700*. Repeat for all data you want to save.

```{r write_geodata}
write_sf(
  obj = left_join(london_27700, cycle_hire_by_area_sum), # object to write
  dsn = here("foss4g_R_workshop.gpkg"), # destination file
  layer = "london_boroughs_27700",  # layer name
  append = FALSE)  # options

write_sf(
  left_join(boroughs_centroids , cycle_hire_by_area_sum),
  dsn = here("foss4g_R_workshop.gpkg"),
  layer = "boroughs_centroids_27700", 
  append = FALSE)

write_sf(
  obj = left_join(cycle_hire_27700, cycle_hire_by_area_sum),
  dsn = here("foss4g_R_workshop.gpkg"),
  layer = "cycle_hire_27700",
  append = FALSE)
```

:::: {.infobox .tip data-latex="note"}

We used the `here()` function as it preserve the project file hierarchy. 
It works better in RStudio but it is still useful with Jupyter notebooks.

The dataset where joined by their GSS_CODE. 
You can specify the "by" statement, but for the sake of readability, it is not show here.

The `append = FALSE` ensure you can write on existing layer, it is optional.

::::


```{r here, eval=FALSE}
print(here())  # print the project directory
list.files(here()) # list the files in the project directory
```

### Check data

{sf} provides an `st_layers()` function that is useful to see the content of a dataset.
 
```{r check_gpkg}
st_layers(dsn = here("foss4g_R_workshop.gpkg"))
```
